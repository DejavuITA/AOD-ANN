{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "# numpy (math) libary\n",
    "import numpy as np\n",
    "\n",
    "from os import walk\n",
    "\n",
    "path1 = '../../../data/'\n",
    "\n",
    "# torch library and sublibraries\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = [] # empty list of files\n",
    "for (dirpath, dirnames, filenames) in walk(path1):\n",
    "    f.extend(filenames)\n",
    "\n",
    "# sort list alphabetically\n",
    "f.sort()\n",
    "# remove non .ssv files from list\n",
    "f = [x for x in f if x[-4:]==\".ssv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('list of input files:\\n* ',f)\n",
    "\n",
    "temp = np.loadtxt(path1+f[0])\n",
    "data = {}\n",
    "\n",
    "data['x'] = np.copy(temp)[:,3:-1]\n",
    "data['c'] = np.copy(temp)[:,-1]\n",
    "\n",
    "print('\\ninput data has shape:\\tx ',  data['x'].shape)\n",
    "print( 'target data has shape:\\tc ', data['c'].shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize data in the range [0,1]\n",
    "data['nx'] = np.nan*np.empty(data['x'].shape)\n",
    "\n",
    "for jj in range(data['x'].shape[1]):\n",
    "    data['nx'][:,jj] = (data['x'][:,jj]-np.amin(data['x'][:,jj]))/(np.amax(data['x'][:,jj])-np.amin(data['x'][:,jj]))\n",
    "\n",
    "if 0:\n",
    "    fig = plt.figure(figsize=(3*6.4, 2*4.8)) # default = 6.4, 4.8\n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "    ax1.plot(data['nx'])\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide training and test sets\n",
    "train = {}\n",
    "test = {}\n",
    "\n",
    "# The problem is to train the network as well as possible using only\n",
    "# on data from \"speakers\" 0-47, and then to test the network on\n",
    "# speakers 48-89, reporting the number of correct classifications\n",
    "# in the test set.\n",
    "\n",
    "# setting '0'\n",
    "default    = [48*11, 42*11]\n",
    "# setting '1'\n",
    "\n",
    "setting = 0\n",
    "if setting == 0:\n",
    "    train['x'] = np.copy(data['nx'][:default[0],:])\n",
    "    train['c'] = np.copy(data['c'][:default[0]])\n",
    "    \n",
    "    test['x']  = np.copy(data['nx'][-default[1]:,:])\n",
    "    test['c']  = np.copy(data['c'][-default[1]:])\n",
    "#elif setting == 1:\n",
    "\n",
    "print('\\ntrain set')    \n",
    "print(train['x'].shape)\n",
    "print(train['c'].shape)\n",
    "\n",
    "print('\\ntest set')\n",
    "print(test['x'].shape)\n",
    "print(test['c'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create x & y torch Variables\n",
    "x = Variable( torch.from_numpy(train['x']).float() )\n",
    "c = Variable( torch.from_numpy(train['c']).long() )\n",
    "# either input data is float or model becomes doublefloat\n",
    "# https://stackoverflow.com/questions/44717100/pytorch-convert-floattensor-into-doubletensor?rq=1\n",
    "# create \n",
    "x_test = Variable( torch.from_numpy(test['x']).float() )\n",
    "c_test = Variable( torch.from_numpy(test['c']).long() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### import UTILITY functions\n",
    "from modules.graph_utils import *\n",
    "    #\n",
    "    # def show_graph(obj, string='loglog'):\n",
    "    # def print_spec(obj):\n",
    "\n",
    "### import NETWORK LOOPS functions\n",
    "from modules.network_loops import *\n",
    "    #\n",
    "    # def run_training(obj, train_x, train_y, valid_x, valid_y):\n",
    "    # def run_test(obj, test_x, test_y, verbose=True):\n",
    "\n",
    "from modules.models import *\n",
    "    #\n",
    "    # class Baseline(torch.nn.Module):\n",
    "    #     def __init__(self, D_in, H, D_out, n):\n",
    "    #     def forward(self, x, n, NL_out=False):\n",
    "    # class BaseSigmoid(torch.nn.Module):\n",
    "    #     def __init__(self, D_in, H, D_out, n):\n",
    "    #     def forward(self, x, n, NL_out=False):\n",
    "    # class BestFitSigmoid(torch.nn.Module):\n",
    "    #     def __init__(self, D_in, H, D_out, n):\n",
    "    #     def forward(self, x, n, NL_out=False):\n",
    "    #\n",
    "    # def generate_entry(obj, verbose = False):\n",
    "\n",
    "# prints errors in semi-log axis\n",
    "show_type = 'lin'\n",
    "\n",
    "# some colors\n",
    "colors = (('xkcd:orange', 'xkcd:red'),#\n",
    "          ('xkcd:blue', 'xkcd:purple'),#\n",
    "          ('xkcd:green', 'xkcd:lime'),#\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### dimensions of \n",
    "# N is batch size\n",
    "N     = train['x'].shape[0]\n",
    "# D_in is input dimension\n",
    "D_in  = train['x'].shape[1]\n",
    "# H*n is the hidden layer dimension\n",
    "H     = 11\n",
    "n     = 8\n",
    "# is the last hidden layer size\n",
    "D_out = 11\n",
    "\n",
    "# numer of epochs\n",
    "epochs = int(1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### model settings\n",
    "k = 1e-2\n",
    "base_lr = k*5e0\n",
    "sigm_lr = k*12\n",
    "best_lr = k*.65e-1\n",
    "\n",
    "base_mom = 0.25\n",
    "sigm_mom = 0.25\n",
    "best_mom = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings: '' name, H = width of hidden layers, n = number of hidden H-layers,\n",
    "#           NL_out = nonlinear output layer/sum-only output layer,\n",
    "#           'model'\n",
    "#           'criterion' and parameters\n",
    "#           'optimizer' and parameters\n",
    "\n",
    "LL = []\n",
    "#for size in [[11,2], [11,3], [22,2], [22,3]]:\n",
    "#    for NL_type in [ ['base', base_lr, base_mom, False],\n",
    "#                      ['sigmoid', sigm_lr, sigm_mom, True],\n",
    "#                      ['bestfit', best_lr, best_mom, True]\n",
    "#                    ]:\n",
    "#        LL.append(\n",
    "#            [['%s %dx%d'%(NL_type[0], size[0], size[1]), N, D_in, size[0], size[1], D_out, NL_type[3], epochs],\n",
    "#             NL_type[0],\n",
    "#             'CEL', [True],\n",
    "#             'SGD', [NL_type[1], NL_type[2]],\n",
    "#             'StepLR', [100, 0.99]\n",
    "#            ]\n",
    "#        )\n",
    "size = [11,2]\n",
    "NL_type = ['sigmoid', sigm_lr, sigm_mom, False]\n",
    "rep = 30\n",
    "par_size = 5\n",
    "#for lrr in np.logspace(-1,-0.7,par_size):\n",
    "for mom in np.linspace(0,0.5,par_size):\n",
    "    for jj in range(rep):\n",
    "        LL.append(\n",
    "            [['%d mom %.1f'%(jj,mom), N, D_in, size[0], size[1], D_out, NL_type[3], epochs],\n",
    "             NL_type[0],\n",
    "             'CEL', [True],\n",
    "             #'SGD', [NL_type[1], NL_type[2]],\n",
    "             #'SGD', [lrr, NL_type[2]],\n",
    "             'SGD', [NL_type[1], mom],\n",
    "             'StepLR', [100, 0.99]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "print(len(LL))\n",
    "\n",
    "models = {}\n",
    "results = []\n",
    "\n",
    "verb=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii in range(len(LL)):\n",
    "    models[ii] = generate_entry(LL[ii], verbose=verb)\n",
    "    run_training(models[ii], x, c, x_test, c_test)\n",
    "    results.append( max(models[jj][-3][:]) )\n",
    "    print('%s\\t%.2f%%'%(models[ii][0][0],results[ii]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(models, show_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii,mm in models.items():\n",
    "    print('%s\\t%3.2f %%'%(models[ii][0][0], results[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(par_size):\n",
    "    print('{:.2f}: ({:.2f} ± {:.2f})%'.format(models[rep*jj][5][1],np.average(results[rep*jj:rep*(jj+1)]),np.std(results[rep*jj:rep*(jj+1)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_graph(models, show_type)\n",
    "#\n",
    "#for ii,mm in models.items():\n",
    "#    print('%s\\t%3.2f %%'%(models[ii][0][0], results[ii]))\n",
    "#\n",
    "#print('({:.2f} ± {:.2f})%'.format(np.average(results[:]),np.std(results[:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
